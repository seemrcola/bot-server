import { ChatOpenAI } from "@langchain/openai";
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
} from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { BaseMessage } from "@langchain/core/messages";
import { createLogger } from '../../utils/logger.js';
import { MCPAgent } from '../../mcp/index.js';

// ä»ç¯å¢ƒå˜é‡ä¸­è·å–LLMé…ç½®
const LLMApiKey = process.env["LLM_API_KEY"];
const LLMName = process.env["LLM_MODEL"] || 'deepseek-chat';
const LLMUrl = process.env["LLM_BASE_URL"];

// ç³»ç»Ÿæç¤ºè¯ - ç¡®ä¿å›å¤æ ¼å¼æ­£ç¡®å’Œä¸“ä¸š
const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·éµå¾ªä»¥ä¸‹å›å¤è§„èŒƒï¼š

1. **ä»£ç å›å¤æ ¼å¼**ï¼šå½“ç”¨æˆ·è¯·æ±‚ä»£ç æ—¶ï¼Œè¯·ä½¿ç”¨Markdownä»£ç å—æ ¼å¼ï¼š
   - JavaScriptä»£ç ï¼šä½¿ç”¨ \`\`\`javascript ä»£ç å—
   - Pythonä»£ç ï¼šä½¿ç”¨ \`\`\`python ä»£ç å—
   - å…¶ä»–è¯­è¨€ï¼šä½¿ç”¨ç›¸åº”çš„è¯­è¨€æ ‡è¯†ç¬¦

2. **å›å¤é£æ ¼**ï¼š
   - ä¿æŒå‹å¥½ã€ä¸“ä¸šå’Œæœ‰ç”¨çš„æ€åº¦
   - æä¾›æ¸…æ™°ã€å‡†ç¡®çš„å›ç­”
   - å¦‚æœç”¨æˆ·ç”¨ä¸­æ–‡æé—®ï¼Œè¯·ç”¨ä¸­æ–‡å›å¤
   - å¦‚æœç”¨æˆ·ç”¨è‹±æ–‡æé—®ï¼Œè¯·ç”¨è‹±æ–‡å›å¤

3. **ä»£ç ç¤ºä¾‹**ï¼š
   - æä¾›å®Œæ•´ã€å¯è¿è¡Œçš„ä»£ç ç¤ºä¾‹
   - æ·»åŠ å¿…è¦çš„æ³¨é‡Šè¯´æ˜
   - è§£é‡Šä»£ç çš„åŠŸèƒ½å’Œç”¨é€”

4. **æ ¼å¼è¦æ±‚**ï¼š
   - ä½¿ç”¨é€‚å½“çš„Markdownæ ¼å¼
   - ä¿æŒå›å¤ç»“æ„æ¸…æ™°
   - é¿å…è¿‡äºå†—é•¿çš„è§£é‡Šï¼Œä½†ç¡®ä¿ä¿¡æ¯å®Œæ•´

è¯·ç¡®ä¿ä½ çš„å›å¤æ—¢ä¸“ä¸šåˆæ˜“äºç†è§£ã€‚`;

// åˆ›å»ºloggerå®ä¾‹
const logger = createLogger('ChatService');

/**
 * å¿«é€Ÿåˆ¤æ–­æ¶ˆæ¯æ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨
 * ä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼Œé¿å…å®Œæ•´çš„LLMè°ƒç”¨
 */
async function checkIfNeedsToolCall(agent: MCPAgent, message: string): Promise<boolean> {
  // è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
  const status = agent.getStatus();
  const availableTools = status.registeredTools || [];

  // ç®€å•çš„å…³é”®è¯åŒ¹é…
  const lowerMessage = message.toLowerCase();

  // æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·åç§°
  for (const tool of availableTools) {
    if (lowerMessage.includes(tool.toLowerCase())) {
      return true;
    }
  }

  // æ£€æŸ¥å¸¸è§çš„å·¥å…·è°ƒç”¨å…³é”®è¯
  const toolCallKeywords = [
    'jojo', 'ã‚´ã‚´ã‚´', 'mudamuda', 'ç„¡é§„',
    'è°ƒç”¨', 'ä½¿ç”¨', 'å·¥å…·', 'tool', 'call'
  ];

  for (const keyword of toolCallKeywords) {
    if (lowerMessage.includes(keyword.toLowerCase())) {
      return true;
    }
  }

  return false;
}

/**
 * åˆ›å»ºæ¸è¿›å¼å·¥å…·è°ƒç”¨æµå¼è¾“å‡º
 * ä½¿ç”¨MCP Agentçš„æ–°æµå¼å¤„ç†æ–¹æ³•
 */
async function* createProgressiveToolCallStream(
  agent: MCPAgent,
  userMessage: string,
  context: any
): AsyncIterable<string> {
  // ç›´æ¥ä½¿ç”¨Agentçš„æµå¼å¤„ç†æ–¹æ³•
  yield* agent.processMessageStream(userMessage, context);
}



// MCPä»£ç†å•ä¾‹
let mcpAgent: MCPAgent | null = null;

/**
 * åˆå§‹åŒ–MCPä»£ç†
 */
async function initMCPAgent(): Promise<MCPAgent | null> {
  try {
    if (!mcpAgent) {
      logger.info('Initializing MCP Agent');
      
      // åˆ›å»ºMCP Agentå®ä¾‹
      mcpAgent = new MCPAgent();

      // é…ç½®MCP Agentçš„LLM æ”¯æŒé“¾å¼é…ç½®
      mcpAgent.configureLLM({
        apiKey: LLMApiKey || '',
        model: LLMName || '',
        configuration: {
          baseURL: LLMUrl || ''
        }
      });

      await mcpAgent.initialize();
      logger.info('MCP Agent initialized successfully ğŸ‰ğŸ‰ğŸ‰');
    }
    return mcpAgent;
  } catch (error) {
    logger.warn('Failed to initialize MCP Agent, continuing without MCP', error);
    return null;
  }
}

/**
 * è¿è¡Œä¸€ä¸ªæ”¯æŒå¯¹è¯å†å²å’ŒMCPå·¥å…·è°ƒç”¨çš„æµå¼èŠå¤©é“¾ã€‚
 * ä¼šè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨MCPå·¥å…·ï¼Œæ— éœ€å¤–éƒ¨æ§åˆ¶ã€‚
 *
 * @param {BaseMessage[]} messages - ä¸€ä¸ªåŒ…å«å¯¹è¯å†å²çš„æ¶ˆæ¯æ•°ç»„ã€‚
 * @param {string} sessionId - å¯é€‰çš„ä¼šè¯IDï¼Œç”¨äºMCPä¸Šä¸‹æ–‡
 * @returns {Promise<AsyncIterable<string>>} è¿”å›ä¸€ä¸ª Promiseï¼Œè¯¥ Promise è§£æä¸ºä¸€ä¸ªå¯å¼‚æ­¥è¿­ä»£çš„æµã€‚
 * @throws {Error} å¦‚æœ `LLM_API_KEY` ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œåˆ™æŠ›å‡ºé”™è¯¯ã€‚
 */
export async function runChatStream(messages: BaseMessage[], sessionId?: string): Promise<AsyncIterable<string>> {
  if (!LLMApiKey) {
    throw new Error("LLM_API_KEY environment variable not set");
  }

  let finalMessages = messages;
  const lastMessage = messages[messages.length - 1];
  const userMessage = lastMessage?.content as string;

  if (userMessage) {
    try {
      const agent = await initMCPAgent();
      if (agent && agent.isInitialized()) {
        logger.info('Checking if message needs MCP processing...');

        // å…ˆå¿«é€Ÿåˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨ï¼ˆä¸æ‰§è¡Œå®Œæ•´å¤„ç†ï¼‰
        const needsToolCall = await checkIfNeedsToolCall(agent, userMessage);

        if (needsToolCall) {
          logger.info('Message needs tool call, using progressive streaming...');

          // ä½¿ç”¨æ¸è¿›å¼æµå¼å¤„ç†å·¥å…·è°ƒç”¨
          return createProgressiveToolCallStream(agent, userMessage, {
            messages,
            sessionId: sessionId || 'default',
          });
        } else {
          logger.info('Simple chat detected, using direct LLM streaming...');
          // ç®€å•å¯¹è¯ï¼Œç›´æ¥ä½¿ç”¨LLMæµå¼å¤„ç†ï¼Œä¸ç»è¿‡MCP Agent
          // è¿™æ ·å¯ä»¥è·å¾—çœŸæ­£çš„æµå¼è¾“å‡º
        }

      } else {
        logger.info('MCP Agent not available, using regular chat');
      }
    } catch (error) {
      logger.warn('Error during MCP processing, falling back to regular chat', error);
    }
  }

  // -- å¦‚æœAgentæ²¡æœ‰ç›´æ¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œåˆ™ç»§ç»­æ‰§è¡ŒLLMè°ƒç”¨ --

  const chatModel = getChatModel();
  const prompt = ChatPromptTemplate.fromMessages([
    ["system", systemPrompt],
    /**
     * åˆ›å»ºå ä½ç¬¦ï¼šåœ¨æç¤ºæ¨¡æ¿ä¸­é¢„ç•™ä¸€ä¸ªä½ç½®ï¼Œåä¸º "messages"
     * è¿™ä¸ªå ä½ç¬¦å¯èƒ½ä¼šåœ¨åç»­çš„é€»è¾‘ä¸­è¢«å¡«å……
     */
    new MessagesPlaceholder("messages"),
  ]);

  const outputParser = new StringOutputParser();              // è¾“å‡ºè§£æå™¨ å°†æ¨¡å‹è¾“å‡ºè§£æä¸ºå­—ç¬¦ä¸²
  const chain = prompt.pipe(chatModel).pipe(outputParser);    // åˆ›å»ºé“¾å¼è°ƒç”¨ å°†æç¤ºæ¨¡æ¿ã€æ¨¡å‹å’Œè¾“å‡ºè§£æå™¨è¿æ¥èµ·æ¥

  logger.info("Streaming chat with DeepSeek...", {
    messageCount: finalMessages.length,
    hasToolResult: finalMessages !== messages,
    sessionId: sessionId || 'default'
  });

  // è°ƒç”¨æµå¼å“åº”
  const stream = await chain.stream({
    messages: finalMessages, // è¿™ä¸ªæ¶ˆæ¯ä¼šå¡«å……åˆ°ä¸Šé¢çš„å ä½ç¬¦ä¸Š
  });

  return stream;
}

/**
 * è·å–èŠå¤©æ¨¡å‹é…ç½®
 */
function getChatModel(): ChatOpenAI {  
  const config: any = {
    apiKey: LLMApiKey,
    model: LLMName,
    temperature: 0.7,
    streaming: true,
    configuration: {
      baseURL: LLMUrl
    }
  };
  
  const model = new ChatOpenAI(config);
  return model;
}

/**
 * å…³é—­MCPä»£ç†
 */
export async function shutdownMCPAgent(): Promise<void> {
  if (mcpAgent) {
    logger.info('Shutting down MCP Agent');
    await mcpAgent.shutdown();
    mcpAgent = null;
    logger.info('MCP Agent shutdown completed');
  }
}

/**
 * è·å–MCPä»£ç†çŠ¶æ€
 */
export function getMCPAgentStatus(): any {
  if (!mcpAgent) {
    return { 
      initialized: false, 
      enabled: true, // MCP é»˜è®¤å¯ç”¨ï¼Œç”±é…ç½®ä¸­å¿ƒç®¡ç†
      reason: 'Agent not initialized'
    };
  }
  return {
    ...mcpAgent.getStatus(),
    enabled: true // MCP é»˜è®¤å¯ç”¨ï¼Œç”±é…ç½®ä¸­å¿ƒç®¡ç†
  };
}
